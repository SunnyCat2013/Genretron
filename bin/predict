#!/usr/bin/env python

import re
import os
import argparse
import numpy
from progress.bar import Bar
from pylearn2.utils import serial, string_utils
from pylearn2.config import yaml_parse
from genretron.gtzan import GTZAN
from pylearn2.datasets.npy_npz import NpzDataset
from pylearn2.datasets.mnist import MNIST
from sklearn.metrics import *
from theano import function

gtzan_params = {
    "seconds": 5.0,
    "seed": 1234,
    "balanced_splits": True,
    "preprocessor": "znormalizer",
    "verbose": True,
    "print_params": False,
    "use_whole_song": True
}

mnist_params = {
    'train': {'which_set': 'train', 'start': 0, 'stop': 50000},
    'valid': {'which_set': 'train', 'start': 50000, 'stop': 60000},
    'test': {'which_set': 'test', 'stop': 10000}
}


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('out')
    parser.add_argument('models', nargs='+')
    return parser.parse_args()


def load_dataset(model, which_set):
    dataset_proxy = yaml_parse.load(model.dataset_yaml_src, instantiate=False)
    dataset_params = {k: string_utils.preprocess(str(v))
                      for k, v in dataset_proxy.keywords.items()}
    if dataset_proxy.callable is NpzDataset:  # GTZAN
        dataset_params['key'] = which_set + '_X'
        dataset_params['target_key'] = which_set + '_y'
    elif dataset_proxy.callable is MNIST:
        dataset_params = mnist_params[which_set]
    else:
        raise NotImplementedError
    return dataset_proxy.callable(**dataset_params)


def get_space(model):
    if model.dataset_yaml_src.find('vector') > 0:
        return 'vector'
    if model.dataset_yaml_src.find('conv2d') > 0:
        return 'conv2d'


def get_classifier(model):
    X = model.get_input_space().make_theano_batch()
    y = model.fprop(X)
    f = function([X], y, allow_input_downcast=True)
    return f


def get_X(dataset):
    if isinstance(dataset, MNIST):
        return dataset.X
    X = dataset.view_converter.design_mat_to_topo_view(dataset.X)
    if X.shape[1:] == (513, 1, 1):
        X = numpy.squeeze(X)
    return X


def get_y_true(dataset):
    if isinstance(dataset, NpzDataset):
        return numpy.argmax(dataset.y, axis=1)
    elif isinstance(dataset, MNIST):
        return numpy.squeeze(dataset.y)


def get_y_true_mv(dataset, ntracksegnment):
    return get_y_true(dataset)[::ntracksegnment]


def get_normalized_model_name(model_path):
    # assuming it ends with -best.pkl
    return os.path.basename(model_path).split('-best.pkl')[0].replace('-', '_')


def get_progressive_model_number(model_path):
    return os.path.basename(os.path.dirname(os.path.dirname(model_path)))


def get_segments_ids(gtzan):
    segments_ids = gtzan.get_track_ids(gtzan.which_set)
    if gtzan.space == 'vector':
        segments_ids = gtzan.track_ids_to_frame_ids(segments_ids)
    return segments_ids


def get_ntracksegments(gtzan):
    if gtzan.space == 'conv2d':
        return gtzan.ntracksegments
    if gtzan.space == 'vector':
        return gtzan.wins_per_track * gtzan.ntracksegments


def get_currentconf(model_path):
    return os.path.join(
        os.path.dirname(os.path.dirname(model_path)), 'current.conf')


def get_hyperparameters(model_path):
    currentconf = get_currentconf(model_path)
    hp = {}
    for line in open(currentconf, 'r'):
        match = re.match(r"^hyper_parameters\.(.+) = (.+)$", line)
        if match:
            hp[match.group(1)] = float(match.group(2))
    return hp


def predict(models):
    sets = ['train', 'valid', 'test']
    y_trues = numpy.zeros(
        (len(args.models), len(sets)), dtype=numpy.ndarray)
    y_true_mvs = numpy.zeros_like(y_trues)
    y_preds = numpy.zeros_like(y_trues)
    y_pred_mvs = numpy.zeros_like(y_trues)

    l1s = numpy.zeros(len(args.models))
    fls = numpy.zeros(len(args.models))

    labels = ""

    bar = Bar('Processing', max=len(args.models) * len(sets))
    for mi, model_path in enumerate(args.models):
        # load learned model
        model = serial.load(model_path)
        hyper_parameters = get_hyperparameters(model_path)

        l1s[mi] = hyper_parameters.get('l1', numpy.nan)
        fls[mi] = hyper_parameters.get('fl', numpy.nan)

        for si, which_set in enumerate(sets):
            dataset = load_dataset(model, which_set)

            # load GTZAN
            if isinstance(dataset, NpzDataset):
                gtzan_params['which_set'] = which_set
                gtzan_params['space'] = get_space(model)
                gtzan = GTZAN(**gtzan_params)
                labels = gtzan.genres
                ntracksegments = get_ntracksegments(gtzan)
                segments_ids = get_segments_ids(gtzan)
            elif isinstance(dataset, MNIST):
                labels = [str(i) for i in range(10)]
            else:
                raise NotImplementedError

            # set up symbolic expressions
            f = get_classifier(model)

            # get X
            X = get_X(dataset)

            # get y_true
            y_true = get_y_true(dataset)
            y_trues[mi][si] = y_true
            if isinstance(dataset, NpzDataset):
                y_true_mv = get_y_true_mv(dataset, ntracksegments)
                y_true_mvs[mi][si] = y_true_mv

            # get y_pred
            y_pred = numpy.empty_like(y_true)
            if isinstance(dataset, NpzDataset):
                for i, _ in enumerate(segments_ids):
                    x = numpy.expand_dims(X[i], axis=0)
                    y_pred[i] = (numpy.argmax(f(x)[0]))
            elif isinstance(dataset, MNIST):
                y_pred = numpy.argmax(f(X), axis=1)
            else:
                raise NotImplementedError
            y_preds[mi][si] = y_pred

            # get y_pred_mv
            if dataset is NpzDataset:
                y_pred_mv = numpy.apply_along_axis(
                    lambda x: numpy.argmax(numpy.bincount(x)), 1,
                    numpy.split(y_pred, len(y_pred) / ntracksegments))
                y_pred_mvs[mi][si] = y_pred_mv

            bar.next()

    bar.finish()
    return y_trues, y_true_mvs, y_preds, y_pred_mvs, l1s, fls, labels

if __name__ == '__main__':
    args = parse_args()

    y_trues, y_true_mvs, y_preds, y_pred_mvs, l1s, fls, labels = predict(
        args.models)
    numpy.savez(args.out,
                y_trues=y_trues,
                y_true_mvs=y_true_mvs,
                y_preds=y_preds,
                y_pred_mvs=y_pred_mvs,
                l1s=l1s,
                fls=fls,
                labels=labels)
